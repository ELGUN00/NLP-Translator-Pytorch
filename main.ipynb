{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "import torch\n",
    "from torchtext.datasets import multi30k, Multi30k\n",
    "from typing import Iterable, List\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics.text import BLEUScore\n",
    "from transformers.optimization import AdamW\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "import torchmetrics\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('experiments_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
    "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.src_lang = \"de_DE\"\n",
    "tokenizer.tgt_lang = \"en_XX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "c:\\Users\\Admin\\Desktop\\Translator\\env\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3892: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Two young white men are outdoors near many bushes.']\n"
     ]
    }
   ],
   "source": [
    "article_de = [\"Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.\"]\n",
    "model_inputs = tokenizer(article_de, return_tensors=\"pt\",padding=True,truncation=True,)\n",
    "with tokenizer.as_target_tokenizer():\n",
    "    labels = tokenizer('Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.', return_tensors=\"pt\").input_ids\n",
    "generated_tokens = model.generate(\n",
    "    **model_inputs,\n",
    "    forced_bos_token_id=tokenizer.lang_code_to_id[\"en_XX\"]).to('cuda')\n",
    "with tokenizer.as_target_tokenizer():\n",
    "    translate = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "    print(translate)\n",
    "\n",
    "\n",
    "#----Two young, White males are outside near many bushes  --> Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "SRC_LANGUAGE = 'de'\n",
    "TGT_LANGUAGE = 'en'\n",
    "EPOCHS = 10\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = Multi30k(split='valid', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.text import BLEUScore\n",
    "bleu = BLEUScore()\n",
    "eval = []\n",
    "def eval_bleu(tgt,pred):\n",
    "    for t, p in zip(tgt,pred):\n",
    "        res = bleu([p], [[t]])\n",
    "        eval.append(res.item())\n",
    "    val =sum(eval)/len(eval)\n",
    "    return val\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    model.eval()\n",
    "    val_iter = Multi30k(split='valid', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "    val_dataloader = DataLoader(val_iter, batch_size=16)\n",
    "    arr = []\n",
    "    batch_iterator = tqdm_notebook(train_dataloader,total=len(list(val_dataloader)))\n",
    "    for src, tgt in batch_iterator:\n",
    "        model_inputs = tokenizer(src, return_tensors=\"pt\",padding=True,truncation=True,)\n",
    "        generated_tokens = model.generate(\n",
    "            **model_inputs,\n",
    "            forced_bos_token_id=tokenizer.lang_code_to_id[\"en_XX\"]\n",
    "        )\n",
    "        with tokenizer.as_target_tokenizer():\n",
    "            translate = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "        val = eval_bleu(tgt,translate)\n",
    "        arr.append(val)\n",
    "    res =sum(arr)/len(arr)\n",
    "    if writer:\n",
    "            metric = torchmetrics.CharErrorRate()\n",
    "            cer = metric(tgt, translate)\n",
    "            writer.add_scalar('validation cer', cer)\n",
    "            writer.flush()\n",
    "\n",
    "            metric = torchmetrics.WordErrorRate()\n",
    "            wer = metric(tgt, translate)\n",
    "            writer.add_scalar('validation wer', wer)\n",
    "            writer.flush()\n",
    "\n",
    "            writer.add_scalar('validation BLEU', res)\n",
    "            writer.flush()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tuning():\n",
    "    print('Start fine-tuning')  \n",
    "    optimizer = AdamW(model.parameters(), lr=1e-4)\n",
    "    model.train()\n",
    "    for i in range(EPOCHS):\n",
    "        losses = 0\n",
    "        batch_iterator = tqdm_notebook(train_dataloader,total=len(list(train_dataloader)) ,desc=f\"Processing Epoch {i:02d}\")\n",
    "        for src, tgt in batch_iterator:\n",
    "                model_inputs = tokenizer(src, return_tensors=\"pt\",padding=True,truncation=True)\n",
    "                with tokenizer.as_target_tokenizer():\n",
    "                        labels = tokenizer(list(tgt), return_tensors=\"pt\",padding=True,truncation=True).input_ids\n",
    "                optimizer.zero_grad()\n",
    "                output = model(**model_inputs,labels=labels)\n",
    "                loss = output.loss\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                losses += loss.item()\n",
    "        losses = losses / len(list(train_dataloader))\n",
    "        writer.add_scalar('train loss', losses, i)\n",
    "        writer.flush()\n",
    "        print(f'Epoch: {i}, Losses: {losses}')\n",
    "        evaluate()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Start process-------\n",
      "Start fine-tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\Desktop\\Translator\\env\\Lib\\site-packages\\transformers\\optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\Desktop\\Translator\\env\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\combining.py:337: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
      "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3293d01ed63547aba79fa7aaecd6d5d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Epoch 00:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Losses: 1.623460367321968\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59772eb936ad4ca4930125adc3f9f914",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\Desktop\\Translator\\env\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:61: FutureWarning: Importing `CharErrorRate` from `torchmetrics` was deprecated and will be removed in 2.0. Import `CharErrorRate` from `torchmetrics.text` instead.\n",
      "  _future_warning(\n",
      "c:\\Users\\Admin\\Desktop\\Translator\\env\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:61: FutureWarning: Importing `WordErrorRate` from `torchmetrics` was deprecated and will be removed in 2.0. Import `WordErrorRate` from `torchmetrics.text` instead.\n",
      "  _future_warning(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a999bbf480a44f139e9574873d956445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Epoch 01:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Losses: 0.30189129314385355\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5d612754f1f4d9591f68efba0fb799d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88bbf247e09143fbb583f8ecd9573a98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Epoch 02:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Losses: 0.14805128891021013\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab4f47b663334d249c49a828e235869d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d43bcaee68b449d96b430842b69c967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Epoch 03:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Losses: 0.0983183472417295\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c8e9a549abf495bb1e564febe806421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcfb5cc783994edb917cde3012a89f5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Epoch 04:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Losses: 0.07369236648082733\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f58dd949ece84372be47dbe045824946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a03438d1d1b4ad2b8ba3fb3e5d4f589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Epoch 05:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Losses: 0.05989678291371092\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4743c66a13754d1584dc5961ed71c986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8045608d0e641c28c637f703df0ef5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Epoch 06:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Losses: 0.04806271899724379\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a4e4271b3442cab5ee682a9970cb10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7d24a52908742b0a5b83371f7994e64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Epoch 07:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Losses: 0.04730839545663912\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "facbbc0016a843ec9240392cb7779466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29b9a1a179714c29bd636340ccb6e7e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Epoch 08:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Losses: 0.07323535207251552\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03ecce60c73c453086677c20f5712320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8baa2391c504368bcf9202883493f6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Epoch 09:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Losses: 0.03457020396308508\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d84f5b0410834a1199886c58cd73df30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bc68ed6f6624e6a93f2f4fbfa40e28e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------End process------\n"
     ]
    }
   ],
   "source": [
    "print('-------Start process-------')\n",
    "fine_tuning()\n",
    "evaluate()\n",
    "print('-------End process------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
